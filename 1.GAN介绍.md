Adversarial training is the coolest thing since sliced bread
对抗性训练是有史以来最酷的事情
​

## 各种各样的GAN
可以看 [https://github.com/hindupuravinash/the-gan-zoo](https://github.com/hindupuravinash/the-gan-zoo)
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637395251056-2013a99f-f310-4d42-a87d-c5e0d70148ac.png)
xxGAN，英文字母有限，经常崇明，到如今已经有三百多中GAN ，GAN变为很重要的技术
​

## GAN的基本概念
#### 生成器
图像生成：丢一个向量进去，输出图片，丢不同向量，输出不同图片
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637396236141-a80d9bee-c35e-4e8a-b64e-243747699fcb.png)
句子生成：丢一个向量进去，输出句子，丢不同向量，输出不同句子
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637396266621-360fe906-e758-429d-90cd-f1702c1b30fc.png)
向量-->神经网络/函数-->高维向量
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637396553963-02458254-2b28-4184-a0ef-e4113dc2c069.png)
每一维度对应一个特征，改变向量的每一个元素，例如某一维度代表头发颜色/长度/张嘴：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637396705690-55036cb9-f5f4-4d04-b978-9efe4bc7ee7e.png)

#### 判别器
传入图片，输出一个标量，判别器也是个神经网络/函数
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637396897754-82fe7974-ac3f-4f22-a036-a20227ad67e3.png)
标量越大代表越真实
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637396963756-67286437-a6c4-4088-a001-e90a5e3059ca.png)  

#### 互为天敌
生成器和判别器的关系和天敌一样，例如枯叶蝶和比比鸟的关系
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637398190741-bce2333b-d9a8-4afb-94dc-a9373d5c06a2.png)
生成器逐渐进化生成更真实的动漫头像，判别器也在进化增强自己的判别能力
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637398282684-9370034b-d66a-42b2-96bf-e3156f29d8a5.png)
由此这个技术被称为“对抗” 

#### 互为帮手
师生关系
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637398612739-54af1167-ac26-4df5-8a75-e2299405acbe.png)
为什么老师不自己生成，为什么学生不自己学

#### 生成器VS判别器
那撸多和撒是给的关系
​

## 算法
（1）初始化生成器的参数（随机）
（2）固定住生成器，像其中传输向量，输出图像
（3）从数据库中取出部分真实图片，现在有两组图片，一组是生成的图片，一组是真实的图片
（4）调整判别器的参数，标准是来自数据库的图片是高分，生成的图片是低分
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637401748871-2bf7d287-fb3e-45c8-8a54-467fb202cb0c.png)
（5）固定住判别器，向生成器送入向量，得到生成图片，再把生成图片送入判别器输出一个标量，调整生成器参数，让生成图片得到一个高分
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637402175780-e29ec165-0e4f-4f6b-a133-f5f1b04c0899.png)
（6）重复4，5
实际上，常常把生成器和判别器放在一个大网络内，每次训练都固定几层，去训练其他层。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637402381829-98573f50-b467-42b1-a27c-2057169d00cd.png)

#### 正式算法
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637402481272-f55a00de-b21b-434d-953b-e82363c8d9c4.png)

## 结构化学习
机器学习：找到函数f，使得f: X->Y
回归问题：输出标量
分类问题：输出one-hot
结构预测：输出序列、矩阵、树......
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637408003235-c5391748-67a7-4997-915a-7d64ab820c2a.png)
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637408487095-d6455d46-6759-4509-951d-608a19cb9263.png)

#### 结构化学习的挑战
**One-shot/Zero-shot Learning**
在分类问题中，一个类可能有很多的样本
但在结构化学习中，如果把每个不同的输出都看作一个类的话，每个类可能只对应着一个样本；因为输出空间太大，大部分类都没有样本。如何生成一个从未看过的问题成为关键（要求机器学会创造更加智能）
机器需要有大局观，懂得像素像素间的关系，句子整体和单句的褒贬不一样的问题等等
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637410104803-41c63b5c-17bc-45cb-96a4-8be73196b69a.png)

#### 结构学习方法
生成模型：从组件开始，自底向上
判别模型：从全局开始，自顶向下
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637413758458-33253d2d-8da9-4320-9286-540a193f0b28.png)

## 为什么Generator不能自己学？
生成器的作用 
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637414218288-b45e066d-f0ff-4b3d-b3c2-5cf52bd33c87.png)
 生成器和分类器其实可以用同一种方法训练，但是生成器的输入输出映射如何定义呢，即对于数字1图像应该对应着什么样的向量输入呢？
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637414615762-3378bee8-d9b0-4307-89ca-09b35445a300.png)
我们可以考虑让向量第一维度与图片产生一定的关联（如上图），通常我们确定这种映射是去训练一个编码器Encoder：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637414683480-82d19b43-e026-4f25-9d5f-79ffac608e99.png)
可以用Auto-encoder技术，但是Encoder不能自己trian，必须结合着decoder一起train

#### Auto-encoder
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637414781861-95385134-d3c0-477b-973e-af3fe31efa3c.png)
我们希望训练后的Encoder和decoder，可以做到如下：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637414836687-8c5fb674-fa15-432f-9919-08c72338f0a8.png)
输入输出要尽可能像。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637414900428-bbc8f81c-42fb-4282-a1b0-ed654306c6b8.png)
我们发现，我们这里的Decoder实际上就是Generator，可以拿来产生图片：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637415513111-6aa048d2-8d26-4500-84cc-d48bb41011ba.png)
在输入空间可以看到数字的连续变化：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637415557365-d4dbaef7-07de-45d2-a565-e4880f0c866a.png)
已知对于输入向量a，b有如下输出：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637415797830-a578d1d0-3021-42cb-94d1-bdbee5d4f6e9.png)
那么对于0.5a+0.5b这个输入，由于Generator是非线性的，其输出很可能不再是数字，这个时候需要VAE技术。

#### VAE技术
Encoder不但产生code，还产生一个varias，用噪声去乘这个varias在去和code求和，送到Decoder，可以让Decoder更加稳定，对于一些噪声也能稳定的输出数字。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637415988899-cc42ddad-5c2b-4194-8613-c75e94db372a.png)

#### 我们会遇到的问题
通常Generator生成的图片不太可能和目标完全一样，会做一些妥协。
 ![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637416600582-a375db61-8407-46c3-8b41-fb165b17e46a.png)
人在主观上会认为尽管下两张图有6个像素点的偏差，但是这张图片是可以接受的
也就是说要去考虑像素与像素之间的关系 ，但是最后一层神经元之间几乎无法配合。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637416864045-4d2eb7c4-ab5f-4633-a153-f3e3250ba420.png)
但是我们可以多加几层神经层 
蓝色点云是Generator生成的，绿色的点云是目标，可见不知道componets之间的影响，就会失去很多细节。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637417372819-9fe07b02-5edb-49f2-bb67-c3d1e0981c91.png)

## 为什么判别器不能自己生成？
其实可以生成，但是很卡。
对于判别器，检查component之间的关系的优劣是非常容易的，因为生成器是一个个component独立生成，而判别器接受的是一个完整的图片，可以通过卷积核来判别。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637417784632-d1b401cd-3676-446d-9fce-76fc13dc8383.png)
对于判别器，穷举每一个像素所有颜色的组合，找出分数最高的那一张：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637417998338-894e0037-a288-41b0-91f2-8e83be177564.png)
这要求的算力极大。如果有个算法可以做到这一点，那你可以发顶会了。假设我们有这样一个算法，我们可以把好的数据送入判别器，告诉判别器打高分，把坏的数据集送进去，告诉它打低分。但是我们手上普遍只有好的数据。 如何获取坏数据成为关键，获取坏数据又需要一个好模型，这就陷入了一个死循环。 假设我们得到了坏数据，那么训练过程如下：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637418769546-b44c056d-3e59-4b3a-85df-e37f10016ae3.png)
其实有很多work都是用判别器来生成的：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637418905595-ccd03644-8503-4daf-88cb-bf79e9b2d1cd.png) 
事实上Generator就是解argmax问题诞生的。用generator有如下好处：
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637419410790-55430d70-f6cb-43f2-b76f-193e70a158f7.png)
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637419441479-c4c5f79b-ed43-4c11-a194-7e7e2e96dde7.png)

## 不同GAN之间的对比
![image.png](https://cdn.nlark.com/yuque/0/2021/png/1081210/1637419579265-5270b295-5c63-49ca-bdd2-82e09045eaa8.png)
可以看出GAN对不同参数有非常大的range，VAE比较稳但差一些，难以做到最好
